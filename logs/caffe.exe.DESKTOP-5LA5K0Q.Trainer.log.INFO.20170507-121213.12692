Log file created at: 2017/05/07 12:12:13
Running on machine: DESKTOP-5LA5K0Q
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0507 12:12:13.207639 12780 caffe.cpp:219] Using GPUs 0
I0507 12:12:13.520141 12780 caffe.cpp:224] GPU 0: TITAN X (Pascal)
I0507 12:12:14.142208 12780 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 12:12:14.173458 12780 solver.cpp:44] Initializing solver from parameters: 
test_iter: 38
test_interval: 100
base_lr: 0.005
display: 1
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 800
snapshot_prefix: "examples/Depth_estimation_basedLiu/models/Model_"
solver_mode: GPU
device_id: 0
net: "examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt"
train_state {
  level: 0
  stage: ""
}
average_loss: 1
iter_size: 19
I0507 12:12:14.173458 12780 solver.cpp:87] Creating training net from net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 12:12:14.173458 12780 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0507 12:12:14.173458 12780 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/train.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 12:12:14.173458 12780 layer_factory.cpp:58] Creating layer data
I0507 12:12:14.173458 12780 net.cpp:84] Creating Layer data
I0507 12:12:14.173458 12780 net.cpp:380] data -> data
I0507 12:12:14.173458 12780 net.cpp:380] data -> label
I0507 12:12:14.173458 12780 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/train.txt
I0507 12:12:14.173458 12780 hdf5_data_layer.cpp:94] Number of HDF5 files: 17
I0507 12:12:14.173458 12780 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0507 12:12:15.360975 12780 net.cpp:122] Setting up data
I0507 12:12:15.360975 12780 net.cpp:129] Top shape: 50 3 112 112 (1881600)
I0507 12:12:15.360975 12780 net.cpp:129] Top shape: 50 1 (50)
I0507 12:12:15.360975 12780 net.cpp:137] Memory required for data: 7526600
I0507 12:12:15.360975 12780 layer_factory.cpp:58] Creating layer conv1
I0507 12:12:15.360975 12780 net.cpp:84] Creating Layer conv1
I0507 12:12:15.360975 12780 net.cpp:406] conv1 <- data
I0507 12:12:15.360975 12780 net.cpp:380] conv1 -> conv1
I0507 12:12:16.003309 12780 net.cpp:122] Setting up conv1
I0507 12:12:16.003309 12780 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 12:12:16.003309 12780 net.cpp:137] Memory required for data: 168089800
I0507 12:12:16.003309 12780 layer_factory.cpp:58] Creating layer relu1
I0507 12:12:16.003309 12780 net.cpp:84] Creating Layer relu1
I0507 12:12:16.003309 12780 net.cpp:406] relu1 <- conv1
I0507 12:12:16.003309 12780 net.cpp:367] relu1 -> conv1 (in-place)
I0507 12:12:16.003309 12780 net.cpp:122] Setting up relu1
I0507 12:12:16.003309 12780 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 328653000
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer pool1
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer pool1
I0507 12:12:16.018934 12780 net.cpp:406] pool1 <- conv1
I0507 12:12:16.018934 12780 net.cpp:380] pool1 -> pool1
I0507 12:12:16.018934 12780 net.cpp:122] Setting up pool1
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 368793800
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer conv2
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer conv2
I0507 12:12:16.018934 12780 net.cpp:406] conv2 <- pool1
I0507 12:12:16.018934 12780 net.cpp:380] conv2 -> conv2
I0507 12:12:16.018934 12780 net.cpp:122] Setting up conv2
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 529357000
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer relu2
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer relu2
I0507 12:12:16.018934 12780 net.cpp:406] relu2 <- conv2
I0507 12:12:16.018934 12780 net.cpp:367] relu2 -> conv2 (in-place)
I0507 12:12:16.018934 12780 net.cpp:122] Setting up relu2
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 689920200
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer pool2
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer pool2
I0507 12:12:16.018934 12780 net.cpp:406] pool2 <- conv2
I0507 12:12:16.018934 12780 net.cpp:380] pool2 -> pool2
I0507 12:12:16.018934 12780 net.cpp:122] Setting up pool2
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 730061000
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer conv3
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer conv3
I0507 12:12:16.018934 12780 net.cpp:406] conv3 <- pool2
I0507 12:12:16.018934 12780 net.cpp:380] conv3 -> conv3
I0507 12:12:16.018934 12780 net.cpp:122] Setting up conv3
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 770201800
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer relu3
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer relu3
I0507 12:12:16.018934 12780 net.cpp:406] relu3 <- conv3
I0507 12:12:16.018934 12780 net.cpp:367] relu3 -> conv3 (in-place)
I0507 12:12:16.018934 12780 net.cpp:122] Setting up relu3
I0507 12:12:16.018934 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.018934 12780 net.cpp:137] Memory required for data: 810342600
I0507 12:12:16.018934 12780 layer_factory.cpp:58] Creating layer conv4
I0507 12:12:16.018934 12780 net.cpp:84] Creating Layer conv4
I0507 12:12:16.018934 12780 net.cpp:406] conv4 <- conv3
I0507 12:12:16.018934 12780 net.cpp:380] conv4 -> conv4
I0507 12:12:16.034554 12780 net.cpp:122] Setting up conv4
I0507 12:12:16.034554 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.034554 12780 net.cpp:137] Memory required for data: 850483400
I0507 12:12:16.034554 12780 layer_factory.cpp:58] Creating layer relu4
I0507 12:12:16.034554 12780 net.cpp:84] Creating Layer relu4
I0507 12:12:16.034554 12780 net.cpp:406] relu4 <- conv4
I0507 12:12:16.034554 12780 net.cpp:367] relu4 -> conv4 (in-place)
I0507 12:12:16.034554 12780 net.cpp:122] Setting up relu4
I0507 12:12:16.034554 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.034554 12780 net.cpp:137] Memory required for data: 890624200
I0507 12:12:16.034554 12780 layer_factory.cpp:58] Creating layer conv5
I0507 12:12:16.034554 12780 net.cpp:84] Creating Layer conv5
I0507 12:12:16.034554 12780 net.cpp:406] conv5 <- conv4
I0507 12:12:16.034554 12780 net.cpp:380] conv5 -> conv5
I0507 12:12:16.034554 12780 net.cpp:122] Setting up conv5
I0507 12:12:16.034554 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.034554 12780 net.cpp:137] Memory required for data: 930765000
I0507 12:12:16.034554 12780 layer_factory.cpp:58] Creating layer relu5
I0507 12:12:16.034554 12780 net.cpp:84] Creating Layer relu5
I0507 12:12:16.034554 12780 net.cpp:406] relu5 <- conv5
I0507 12:12:16.034554 12780 net.cpp:367] relu5 -> conv5 (in-place)
I0507 12:12:16.034554 12780 net.cpp:122] Setting up relu5
I0507 12:12:16.034554 12780 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:12:16.034554 12780 net.cpp:137] Memory required for data: 970905800
I0507 12:12:16.034554 12780 layer_factory.cpp:58] Creating layer pool3
I0507 12:12:16.034554 12780 net.cpp:84] Creating Layer pool3
I0507 12:12:16.034554 12780 net.cpp:406] pool3 <- conv5
I0507 12:12:16.034554 12780 net.cpp:380] pool3 -> pool3
I0507 12:12:16.034554 12780 net.cpp:122] Setting up pool3
I0507 12:12:16.034554 12780 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0507 12:12:16.034554 12780 net.cpp:137] Memory required for data: 980941000
I0507 12:12:16.034554 12780 layer_factory.cpp:58] Creating layer fc6
I0507 12:12:16.034554 12780 net.cpp:84] Creating Layer fc6
I0507 12:12:16.034554 12780 net.cpp:406] fc6 <- pool3
I0507 12:12:16.034554 12780 net.cpp:380] fc6 -> fc6
I0507 12:12:16.425187 12780 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 12:12:18.849625 12780 net.cpp:122] Setting up fc6
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 981760200
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer relu6
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer relu6
I0507 12:12:18.849625 12780 net.cpp:406] relu6 <- fc6
I0507 12:12:18.849625 12780 net.cpp:367] relu6 -> fc6 (in-place)
I0507 12:12:18.849625 12780 net.cpp:122] Setting up relu6
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 982579400
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer drop6
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer drop6
I0507 12:12:18.849625 12780 net.cpp:406] drop6 <- fc6
I0507 12:12:18.849625 12780 net.cpp:367] drop6 -> fc6 (in-place)
I0507 12:12:18.849625 12780 net.cpp:122] Setting up drop6
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 983398600
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer fc7
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer fc7
I0507 12:12:18.849625 12780 net.cpp:406] fc7 <- fc6
I0507 12:12:18.849625 12780 net.cpp:380] fc7 -> fc7
I0507 12:12:18.849625 12780 net.cpp:122] Setting up fc7
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 128 (6400)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 983424200
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer relu7
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer relu7
I0507 12:12:18.849625 12780 net.cpp:406] relu7 <- fc7
I0507 12:12:18.849625 12780 net.cpp:367] relu7 -> fc7 (in-place)
I0507 12:12:18.849625 12780 net.cpp:122] Setting up relu7
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 128 (6400)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 983449800
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer fc8
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer fc8
I0507 12:12:18.849625 12780 net.cpp:406] fc8 <- fc7
I0507 12:12:18.849625 12780 net.cpp:380] fc8 -> fc8
I0507 12:12:18.849625 12780 net.cpp:122] Setting up fc8
I0507 12:12:18.849625 12780 net.cpp:129] Top shape: 50 16 (800)
I0507 12:12:18.849625 12780 net.cpp:137] Memory required for data: 983453000
I0507 12:12:18.849625 12780 layer_factory.cpp:58] Creating layer sig8
I0507 12:12:18.849625 12780 net.cpp:84] Creating Layer sig8
I0507 12:12:18.849625 12780 net.cpp:406] sig8 <- fc8
I0507 12:12:18.849625 12780 net.cpp:367] sig8 -> fc8 (in-place)
I0507 12:12:18.865247 12780 net.cpp:122] Setting up sig8
I0507 12:12:18.865247 12780 net.cpp:129] Top shape: 50 16 (800)
I0507 12:12:18.865247 12780 net.cpp:137] Memory required for data: 983456200
I0507 12:12:18.865247 12780 layer_factory.cpp:58] Creating layer fc9
I0507 12:12:18.865247 12780 net.cpp:84] Creating Layer fc9
I0507 12:12:18.865247 12780 net.cpp:406] fc9 <- fc8
I0507 12:12:18.865247 12780 net.cpp:380] fc9 -> fc9
I0507 12:12:18.865247 12780 net.cpp:122] Setting up fc9
I0507 12:12:18.865247 12780 net.cpp:129] Top shape: 50 1 (50)
I0507 12:12:18.865247 12780 net.cpp:137] Memory required for data: 983456400
I0507 12:12:18.865247 12780 layer_factory.cpp:58] Creating layer loss
I0507 12:12:18.865247 12780 net.cpp:84] Creating Layer loss
I0507 12:12:18.865247 12780 net.cpp:406] loss <- fc9
I0507 12:12:18.865247 12780 net.cpp:406] loss <- label
I0507 12:12:18.865247 12780 net.cpp:380] loss -> loss
I0507 12:12:18.865247 12780 net.cpp:122] Setting up loss
I0507 12:12:18.865247 12780 net.cpp:129] Top shape: (1)
I0507 12:12:18.865247 12780 net.cpp:132]     with loss weight 1
I0507 12:12:18.865247 12780 net.cpp:137] Memory required for data: 983456404
I0507 12:12:18.865247 12780 net.cpp:198] loss needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] fc9 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] sig8 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] fc8 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu7 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] fc7 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] drop6 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu6 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] fc6 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] pool3 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu5 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] conv5 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu4 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] conv4 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu3 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] conv3 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] pool2 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu2 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] conv2 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] pool1 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] relu1 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:198] conv1 needs backward computation.
I0507 12:12:18.865247 12780 net.cpp:200] data does not need backward computation.
I0507 12:12:18.865247 12780 net.cpp:242] This network produces output loss
I0507 12:12:18.865247 12780 net.cpp:255] Network initialization done.
I0507 12:12:18.865247 12780 solver.cpp:173] Creating test net (#0) specified by net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 12:12:18.865247 12780 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0507 12:12:18.865247 12780 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/test.txt"
    batch_size: 25
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 12:12:18.865247 12780 layer_factory.cpp:58] Creating layer data
I0507 12:12:18.865247 12780 net.cpp:84] Creating Layer data
I0507 12:12:18.865247 12780 net.cpp:380] data -> data
I0507 12:12:18.865247 12780 net.cpp:380] data -> label
I0507 12:12:18.865247 12780 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/test.txt
I0507 12:12:18.865247 12780 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0507 12:12:20.856495 12780 net.cpp:122] Setting up data
I0507 12:12:20.856495 12780 net.cpp:129] Top shape: 25 3 112 112 (940800)
I0507 12:12:20.856495 12780 net.cpp:129] Top shape: 25 1 (25)
I0507 12:12:20.856495 12780 net.cpp:137] Memory required for data: 3763300
I0507 12:12:20.856495 12780 layer_factory.cpp:58] Creating layer conv1
I0507 12:12:20.856495 12780 net.cpp:84] Creating Layer conv1
I0507 12:12:20.856495 12780 net.cpp:406] conv1 <- data
I0507 12:12:20.856495 12780 net.cpp:380] conv1 -> conv1
I0507 12:12:20.856495 12780 net.cpp:122] Setting up conv1
I0507 12:12:20.856495 12780 net.cpp:129] Top shape: 25 64 112 112 (20070400)
I0507 12:12:20.856495 12780 net.cpp:137] Memory required for data: 84044900
I0507 12:12:20.856495 12780 layer_factory.cpp:58] Creating layer relu1
I0507 12:12:20.856495 12780 net.cpp:84] Creating Layer relu1
I0507 12:12:20.856495 12780 net.cpp:406] relu1 <- conv1
I0507 12:12:20.856495 12780 net.cpp:367] relu1 -> conv1 (in-place)
I0507 12:12:20.856495 12780 net.cpp:122] Setting up relu1
I0507 12:12:20.856495 12780 net.cpp:129] Top shape: 25 64 112 112 (20070400)
I0507 12:12:20.856495 12780 net.cpp:137] Memory required for data: 164326500
I0507 12:12:20.856495 12780 layer_factory.cpp:58] Creating layer pool1
I0507 12:12:20.856495 12780 net.cpp:84] Creating Layer pool1
I0507 12:12:20.856495 12780 net.cpp:406] pool1 <- conv1
I0507 12:12:20.856495 12780 net.cpp:380] pool1 -> pool1
I0507 12:12:20.856495 12780 net.cpp:122] Setting up pool1
I0507 12:12:20.856495 12780 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0507 12:12:20.856495 12780 net.cpp:137] Memory required for data: 184396900
I0507 12:12:20.856495 12780 layer_factory.cpp:58] Creating layer conv2
I0507 12:12:20.856495 12780 net.cpp:84] Creating Layer conv2
I0507 12:12:20.856495 12780 net.cpp:406] conv2 <- pool1
I0507 12:12:20.856495 12780 net.cpp:380] conv2 -> conv2
I0507 12:12:20.872123 12780 net.cpp:122] Setting up conv2
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 264678500
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer relu2
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer relu2
I0507 12:12:20.872123 12780 net.cpp:406] relu2 <- conv2
I0507 12:12:20.872123 12780 net.cpp:367] relu2 -> conv2 (in-place)
I0507 12:12:20.872123 12780 net.cpp:122] Setting up relu2
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 344960100
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer pool2
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer pool2
I0507 12:12:20.872123 12780 net.cpp:406] pool2 <- conv2
I0507 12:12:20.872123 12780 net.cpp:380] pool2 -> pool2
I0507 12:12:20.872123 12780 net.cpp:122] Setting up pool2
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 365030500
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer conv3
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer conv3
I0507 12:12:20.872123 12780 net.cpp:406] conv3 <- pool2
I0507 12:12:20.872123 12780 net.cpp:380] conv3 -> conv3
I0507 12:12:20.872123 12780 net.cpp:122] Setting up conv3
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 385100900
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer relu3
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer relu3
I0507 12:12:20.872123 12780 net.cpp:406] relu3 <- conv3
I0507 12:12:20.872123 12780 net.cpp:367] relu3 -> conv3 (in-place)
I0507 12:12:20.872123 12780 net.cpp:122] Setting up relu3
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 405171300
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer conv4
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer conv4
I0507 12:12:20.872123 12780 net.cpp:406] conv4 <- conv3
I0507 12:12:20.872123 12780 net.cpp:380] conv4 -> conv4
I0507 12:12:20.872123 12780 net.cpp:122] Setting up conv4
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 425241700
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer relu4
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer relu4
I0507 12:12:20.872123 12780 net.cpp:406] relu4 <- conv4
I0507 12:12:20.872123 12780 net.cpp:367] relu4 -> conv4 (in-place)
I0507 12:12:20.872123 12780 net.cpp:122] Setting up relu4
I0507 12:12:20.872123 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.872123 12780 net.cpp:137] Memory required for data: 445312100
I0507 12:12:20.872123 12780 layer_factory.cpp:58] Creating layer conv5
I0507 12:12:20.872123 12780 net.cpp:84] Creating Layer conv5
I0507 12:12:20.872123 12780 net.cpp:406] conv5 <- conv4
I0507 12:12:20.872123 12780 net.cpp:380] conv5 -> conv5
I0507 12:12:20.887749 12780 net.cpp:122] Setting up conv5
I0507 12:12:20.887749 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.887749 12780 net.cpp:137] Memory required for data: 465382500
I0507 12:12:20.887749 12780 layer_factory.cpp:58] Creating layer relu5
I0507 12:12:20.887749 12780 net.cpp:84] Creating Layer relu5
I0507 12:12:20.887749 12780 net.cpp:406] relu5 <- conv5
I0507 12:12:20.887749 12780 net.cpp:367] relu5 -> conv5 (in-place)
I0507 12:12:20.887749 12780 net.cpp:122] Setting up relu5
I0507 12:12:20.887749 12780 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:12:20.887749 12780 net.cpp:137] Memory required for data: 485452900
I0507 12:12:20.887749 12780 layer_factory.cpp:58] Creating layer pool3
I0507 12:12:20.887749 12780 net.cpp:84] Creating Layer pool3
I0507 12:12:20.887749 12780 net.cpp:406] pool3 <- conv5
I0507 12:12:20.887749 12780 net.cpp:380] pool3 -> pool3
I0507 12:12:20.887749 12780 net.cpp:122] Setting up pool3
I0507 12:12:20.887749 12780 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0507 12:12:20.887749 12780 net.cpp:137] Memory required for data: 490470500
I0507 12:12:20.887749 12780 layer_factory.cpp:58] Creating layer fc6
I0507 12:12:20.887749 12780 net.cpp:84] Creating Layer fc6
I0507 12:12:20.887749 12780 net.cpp:406] fc6 <- pool3
I0507 12:12:20.887749 12780 net.cpp:380] fc6 -> fc6
I0507 12:12:23.852746 12780 net.cpp:122] Setting up fc6
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 490880100
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer relu6
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer relu6
I0507 12:12:23.852746 12780 net.cpp:406] relu6 <- fc6
I0507 12:12:23.852746 12780 net.cpp:367] relu6 -> fc6 (in-place)
I0507 12:12:23.852746 12780 net.cpp:122] Setting up relu6
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491289700
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer drop6
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer drop6
I0507 12:12:23.852746 12780 net.cpp:406] drop6 <- fc6
I0507 12:12:23.852746 12780 net.cpp:367] drop6 -> fc6 (in-place)
I0507 12:12:23.852746 12780 net.cpp:122] Setting up drop6
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491699300
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer fc7
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer fc7
I0507 12:12:23.852746 12780 net.cpp:406] fc7 <- fc6
I0507 12:12:23.852746 12780 net.cpp:380] fc7 -> fc7
I0507 12:12:23.852746 12780 net.cpp:122] Setting up fc7
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 128 (3200)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491712100
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer relu7
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer relu7
I0507 12:12:23.852746 12780 net.cpp:406] relu7 <- fc7
I0507 12:12:23.852746 12780 net.cpp:367] relu7 -> fc7 (in-place)
I0507 12:12:23.852746 12780 net.cpp:122] Setting up relu7
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 128 (3200)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491724900
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer fc8
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer fc8
I0507 12:12:23.852746 12780 net.cpp:406] fc8 <- fc7
I0507 12:12:23.852746 12780 net.cpp:380] fc8 -> fc8
I0507 12:12:23.852746 12780 net.cpp:122] Setting up fc8
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 16 (400)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491726500
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer sig8
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer sig8
I0507 12:12:23.852746 12780 net.cpp:406] sig8 <- fc8
I0507 12:12:23.852746 12780 net.cpp:367] sig8 -> fc8 (in-place)
I0507 12:12:23.852746 12780 net.cpp:122] Setting up sig8
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 16 (400)
I0507 12:12:23.852746 12780 net.cpp:137] Memory required for data: 491728100
I0507 12:12:23.852746 12780 layer_factory.cpp:58] Creating layer fc9
I0507 12:12:23.852746 12780 net.cpp:84] Creating Layer fc9
I0507 12:12:23.852746 12780 net.cpp:406] fc9 <- fc8
I0507 12:12:23.852746 12780 net.cpp:380] fc9 -> fc9
I0507 12:12:23.852746 12780 net.cpp:122] Setting up fc9
I0507 12:12:23.852746 12780 net.cpp:129] Top shape: 25 1 (25)
I0507 12:12:23.868351 12780 net.cpp:137] Memory required for data: 491728200
I0507 12:12:23.868351 12780 layer_factory.cpp:58] Creating layer loss
I0507 12:12:23.868351 12780 net.cpp:84] Creating Layer loss
I0507 12:12:23.868351 12780 net.cpp:406] loss <- fc9
I0507 12:12:23.868351 12780 net.cpp:406] loss <- label
I0507 12:12:23.868351 12780 net.cpp:380] loss -> loss
I0507 12:12:23.868351 12780 net.cpp:122] Setting up loss
I0507 12:12:23.868351 12780 net.cpp:129] Top shape: (1)
I0507 12:12:23.868351 12780 net.cpp:132]     with loss weight 1
I0507 12:12:23.868351 12780 net.cpp:137] Memory required for data: 491728204
I0507 12:12:23.868351 12780 net.cpp:198] loss needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] fc9 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] sig8 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] fc8 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu7 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] fc7 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] drop6 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu6 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] fc6 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] pool3 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu5 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] conv5 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu4 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] conv4 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu3 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] conv3 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] pool2 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu2 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] conv2 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] pool1 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] relu1 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:198] conv1 needs backward computation.
I0507 12:12:23.868351 12780 net.cpp:200] data does not need backward computation.
I0507 12:12:23.868351 12780 net.cpp:242] This network produces output loss
I0507 12:12:23.868351 12780 net.cpp:255] Network initialization done.
I0507 12:12:23.868351 12780 solver.cpp:56] Solver scaffolding done.
I0507 12:12:23.868351 12780 caffe.cpp:249] Starting Optimization
I0507 12:12:23.868351 12780 solver.cpp:273] Solving DepthEstimation
I0507 12:12:23.868351 12780 solver.cpp:274] Learning Rate Policy: fixed
I0507 12:12:23.899622 12780 solver.cpp:331] Iteration 0, Testing net (#0)
I0507 12:12:25.337692 12780 solver.cpp:398]     Test net output #0: loss = 18961.4 (* 1 = 18961.4 loss)
I0507 12:12:27.725306 12780 solver.cpp:219] Iteration 0 (-8.05508e-41 iter/s, 3.82413s/1 iters), loss = 22701
I0507 12:12:27.725306 12780 solver.cpp:238]     Train net output #0: loss = 107.614 (* 1 = 107.614 loss)
I0507 12:12:27.726330 12780 sgd_solver.cpp:105] Iteration 0, lr = 0.005
I0507 12:12:30.073725 12780 solver.cpp:219] Iteration 1 (0.426471 iter/s, 2.34482s/1 iters), loss = 15500.7
I0507 12:12:30.073725 12780 solver.cpp:238]     Train net output #0: loss = 9949.11 (* 1 = 9949.11 loss)
I0507 12:12:30.074704 12780 sgd_solver.cpp:105] Iteration 1, lr = 0.005
I0507 12:12:32.432099 12780 solver.cpp:219] Iteration 2 (0.424355 iter/s, 2.35652s/1 iters), loss = 16551.8
I0507 12:12:32.433100 12780 solver.cpp:238]     Train net output #0: loss = 138.891 (* 1 = 138.891 loss)
I0507 12:12:32.434077 12780 sgd_solver.cpp:105] Iteration 2, lr = 0.005
I0507 12:12:34.728070 12780 solver.cpp:219] Iteration 3 (0.435975 iter/s, 2.29371s/1 iters), loss = 23916.9
I0507 12:12:34.728070 12780 solver.cpp:238]     Train net output #0: loss = 75.9424 (* 1 = 75.9424 loss)
I0507 12:12:34.728070 12780 sgd_solver.cpp:105] Iteration 3, lr = 0.005
I0507 12:12:37.026671 12780 solver.cpp:219] Iteration 4 (0.435461 iter/s, 2.29642s/1 iters), loss = 22385.6
I0507 12:12:37.026671 12780 solver.cpp:238]     Train net output #0: loss = 88.7301 (* 1 = 88.7301 loss)
I0507 12:12:37.027673 12780 sgd_solver.cpp:105] Iteration 4, lr = 0.005
I0507 12:12:39.325747 12780 solver.cpp:219] Iteration 5 (0.435388 iter/s, 2.2968s/1 iters), loss = 15323.7
I0507 12:12:39.325747 12780 solver.cpp:238]     Train net output #0: loss = 397.93 (* 1 = 397.93 loss)
I0507 12:12:39.326745 12780 sgd_solver.cpp:105] Iteration 5, lr = 0.005
I0507 12:12:41.625890 12780 solver.cpp:219] Iteration 6 (0.434491 iter/s, 2.30155s/1 iters), loss = 19088.6
I0507 12:12:41.625890 12780 solver.cpp:238]     Train net output #0: loss = 1161.11 (* 1 = 1161.11 loss)
I0507 12:12:41.625890 12780 sgd_solver.cpp:105] Iteration 6, lr = 0.005
I0507 12:12:43.931936 12780 solver.cpp:219] Iteration 7 (0.434653 iter/s, 2.30068s/1 iters), loss = 11063.8
I0507 12:12:43.931936 12780 solver.cpp:238]     Train net output #0: loss = 2491.97 (* 1 = 2491.97 loss)
I0507 12:12:43.932937 12780 sgd_solver.cpp:105] Iteration 7, lr = 0.005
I0507 12:12:46.261404 12780 solver.cpp:219] Iteration 8 (0.428582 iter/s, 2.33328s/1 iters), loss = 18546.5
I0507 12:12:46.261404 12780 solver.cpp:238]     Train net output #0: loss = 3807.58 (* 1 = 3807.58 loss)
I0507 12:12:46.261404 12780 sgd_solver.cpp:105] Iteration 8, lr = 0.005
I0507 12:12:50.299177 12780 solver.cpp:219] Iteration 9 (0.248124 iter/s, 4.03024s/1 iters), loss = 16978.5
I0507 12:12:50.299177 12780 solver.cpp:238]     Train net output #0: loss = 5746.38 (* 1 = 5746.38 loss)
I0507 12:12:50.300179 12780 sgd_solver.cpp:105] Iteration 9, lr = 0.005
I0507 12:12:52.790436 12780 solver.cpp:219] Iteration 10 (0.401695 iter/s, 2.48945s/1 iters), loss = 14952.4
I0507 12:12:52.791435 12780 solver.cpp:238]     Train net output #0: loss = 7528.79 (* 1 = 7528.79 loss)
I0507 12:12:52.792435 12780 sgd_solver.cpp:105] Iteration 10, lr = 0.005
I0507 12:12:55.149822 12780 solver.cpp:219] Iteration 11 (0.423516 iter/s, 2.36118s/1 iters), loss = 16539.5
I0507 12:12:55.149822 12780 solver.cpp:238]     Train net output #0: loss = 7729.08 (* 1 = 7729.08 loss)
I0507 12:12:55.149822 12780 sgd_solver.cpp:105] Iteration 11, lr = 0.005
I0507 12:12:57.493801 12780 solver.cpp:219] Iteration 12 (0.427481 iter/s, 2.33929s/1 iters), loss = 20444.3
I0507 12:12:57.493801 12780 solver.cpp:238]     Train net output #0: loss = 18605.7 (* 1 = 18605.7 loss)
I0507 12:12:57.493801 12780 sgd_solver.cpp:105] Iteration 12, lr = 0.005
I0507 12:12:59.924589 12780 solver.cpp:219] Iteration 13 (0.411593 iter/s, 2.42958s/1 iters), loss = 14438.8
I0507 12:12:59.924589 12780 solver.cpp:238]     Train net output #0: loss = 8570.4 (* 1 = 8570.4 loss)
I0507 12:12:59.924589 12780 sgd_solver.cpp:105] Iteration 13, lr = 0.005
I0507 12:13:02.327386 12780 solver.cpp:219] Iteration 14 (0.416929 iter/s, 2.39849s/1 iters), loss = 13336.8
I0507 12:13:02.327386 12780 solver.cpp:238]     Train net output #0: loss = 7217.95 (* 1 = 7217.95 loss)
I0507 12:13:02.328387 12780 sgd_solver.cpp:105] Iteration 14, lr = 0.005
I0507 12:13:04.697317 12780 solver.cpp:219] Iteration 15 (0.419932 iter/s, 2.38134s/1 iters), loss = 18732.8
I0507 12:13:04.697317 12780 solver.cpp:238]     Train net output #0: loss = 12336.1 (* 1 = 12336.1 loss)
I0507 12:13:04.697317 12780 sgd_solver.cpp:105] Iteration 15, lr = 0.005
I0507 12:13:07.250603 12780 solver.cpp:219] Iteration 16 (0.39408 iter/s, 2.53756s/1 iters), loss = 16631.1
I0507 12:13:07.250603 12780 solver.cpp:238]     Train net output #0: loss = 5298.9 (* 1 = 5298.9 loss)
I0507 12:13:07.251605 12780 sgd_solver.cpp:105] Iteration 16, lr = 0.005
I0507 12:13:09.790299 12780 solver.cpp:219] Iteration 17 (0.394007 iter/s, 2.53803s/1 iters), loss = 15145.6
I0507 12:13:09.790299 12780 solver.cpp:238]     Train net output #0: loss = 3913.44 (* 1 = 3913.44 loss)
I0507 12:13:09.790299 12780 sgd_solver.cpp:105] Iteration 17, lr = 0.005
I0507 12:13:12.450947 12780 solver.cpp:219] Iteration 18 (0.374891 iter/s, 2.66744s/1 iters), loss = 14162.8
I0507 12:13:12.450947 12780 solver.cpp:238]     Train net output #0: loss = 4822.06 (* 1 = 4822.06 loss)
I0507 12:13:12.450947 12780 sgd_solver.cpp:105] Iteration 18, lr = 0.005
I0507 12:13:16.768900 12780 solver.cpp:219] Iteration 19 (0.232 iter/s, 4.31034s/1 iters), loss = 15127.5
I0507 12:13:16.768900 12780 solver.cpp:238]     Train net output #0: loss = 2505.88 (* 1 = 2505.88 loss)
I0507 12:13:16.768900 12780 sgd_solver.cpp:105] Iteration 19, lr = 0.005
I0507 12:13:19.362684 12780 solver.cpp:219] Iteration 20 (0.385052 iter/s, 2.59705s/1 iters), loss = 12840.7
I0507 12:13:19.362684 12780 solver.cpp:238]     Train net output #0: loss = 1864.22 (* 1 = 1864.22 loss)
I0507 12:13:19.362684 12780 sgd_solver.cpp:105] Iteration 20, lr = 0.005
I0507 12:13:21.817529 12780 solver.cpp:219] Iteration 21 (0.40837 iter/s, 2.44876s/1 iters), loss = 13673.2
I0507 12:13:21.817529 12780 solver.cpp:238]     Train net output #0: loss = 1438.84 (* 1 = 1438.84 loss)
I0507 12:13:21.817529 12780 sgd_solver.cpp:105] Iteration 21, lr = 0.005
I0507 12:13:24.213171 12780 solver.cpp:219] Iteration 22 (0.418242 iter/s, 2.39096s/1 iters), loss = 18999.7
I0507 12:13:24.213171 12780 solver.cpp:238]     Train net output #0: loss = 12594 (* 1 = 12594 loss)
I0507 12:13:24.213171 12780 sgd_solver.cpp:105] Iteration 22, lr = 0.005
I0507 12:13:26.531393 12780 solver.cpp:219] Iteration 23 (0.431591 iter/s, 2.31701s/1 iters), loss = 16599.5
I0507 12:13:26.531393 12780 solver.cpp:238]     Train net output #0: loss = 16820.6 (* 1 = 16820.6 loss)
I0507 12:13:26.531393 12780 sgd_solver.cpp:105] Iteration 23, lr = 0.005
I0507 12:13:28.870677 12780 solver.cpp:219] Iteration 24 (0.426637 iter/s, 2.34392s/1 iters), loss = 15745.4
I0507 12:13:28.870677 12780 solver.cpp:238]     Train net output #0: loss = 4877.05 (* 1 = 4877.05 loss)
I0507 12:13:28.870677 12780 sgd_solver.cpp:105] Iteration 24, lr = 0.005
I0507 12:13:31.231658 12780 solver.cpp:219] Iteration 25 (0.423966 iter/s, 2.35868s/1 iters), loss = 20025.2
I0507 12:13:31.231658 12780 solver.cpp:238]     Train net output #0: loss = 1036.64 (* 1 = 1036.64 loss)
I0507 12:13:31.231658 12780 sgd_solver.cpp:105] Iteration 25, lr = 0.005
I0507 12:13:33.605283 12780 solver.cpp:219] Iteration 26 (0.422666 iter/s, 2.36593s/1 iters), loss = 9402.54
I0507 12:13:33.605283 12780 solver.cpp:238]     Train net output #0: loss = 1743.13 (* 1 = 1743.13 loss)
I0507 12:13:33.605283 12780 sgd_solver.cpp:105] Iteration 26, lr = 0.005
I0507 12:13:36.206012 12780 solver.cpp:219] Iteration 27 (0.38436 iter/s, 2.60172s/1 iters), loss = 10655.7
I0507 12:13:36.206012 12780 solver.cpp:238]     Train net output #0: loss = 2229.61 (* 1 = 2229.61 loss)
I0507 12:13:36.206012 12780 sgd_solver.cpp:105] Iteration 27, lr = 0.005
I0507 12:13:38.833017 12780 solver.cpp:219] Iteration 28 (0.381654 iter/s, 2.62017s/1 iters), loss = 21088.6
I0507 12:13:38.833017 12780 solver.cpp:238]     Train net output #0: loss = 2513.17 (* 1 = 2513.17 loss)
I0507 12:13:38.833017 12780 sgd_solver.cpp:105] Iteration 28, lr = 0.005
I0507 12:13:42.819066 12780 solver.cpp:219] Iteration 29 (0.250534 iter/s, 3.99147s/1 iters), loss = 15490
I0507 12:13:42.819066 12780 solver.cpp:238]     Train net output #0: loss = 2484.23 (* 1 = 2484.23 loss)
I0507 12:13:42.819066 12780 sgd_solver.cpp:105] Iteration 29, lr = 0.005
I0507 12:13:45.444095 12780 solver.cpp:219] Iteration 30 (0.381637 iter/s, 2.62029s/1 iters), loss = 12686.8
I0507 12:13:45.444095 12780 solver.cpp:238]     Train net output #0: loss = 3630.22 (* 1 = 3630.22 loss)
I0507 12:13:45.444095 12780 sgd_solver.cpp:105] Iteration 30, lr = 0.005
I0507 12:13:48.016916 12780 solver.cpp:219] Iteration 31 (0.387839 iter/s, 2.57839s/1 iters), loss = 10819.6
I0507 12:13:48.016916 12780 solver.cpp:238]     Train net output #0: loss = 3422.45 (* 1 = 3422.45 loss)
I0507 12:13:48.032519 12780 sgd_solver.cpp:105] Iteration 31, lr = 0.005
I0507 12:13:50.360694 12780 solver.cpp:219] Iteration 32 (0.427151 iter/s, 2.34109s/1 iters), loss = 11683.1
I0507 12:13:50.360694 12780 solver.cpp:238]     Train net output #0: loss = 3872.3 (* 1 = 3872.3 loss)
I0507 12:13:50.360694 12780 sgd_solver.cpp:105] Iteration 32, lr = 0.005
I0507 12:13:52.700067 12780 solver.cpp:219] Iteration 33 (0.430311 iter/s, 2.3239s/1 iters), loss = 17460.4
I0507 12:13:52.700067 12780 solver.cpp:238]     Train net output #0: loss = 6384.9 (* 1 = 6384.9 loss)
I0507 12:13:52.701045 12780 sgd_solver.cpp:105] Iteration 33, lr = 0.005
I0507 12:13:55.085592 12780 solver.cpp:219] Iteration 34 (0.419563 iter/s, 2.38343s/1 iters), loss = 5848.11
I0507 12:13:55.085592 12780 solver.cpp:238]     Train net output #0: loss = 3097.82 (* 1 = 3097.82 loss)
I0507 12:13:55.088572 12780 sgd_solver.cpp:105] Iteration 34, lr = 0.005
I0507 12:13:57.455024 12780 solver.cpp:219] Iteration 35 (0.420064 iter/s, 2.38059s/1 iters), loss = 2427.85
I0507 12:13:57.455024 12780 solver.cpp:238]     Train net output #0: loss = 2290.71 (* 1 = 2290.71 loss)
I0507 12:13:57.470626 12780 sgd_solver.cpp:105] Iteration 35, lr = 0.005
I0507 12:13:59.880189 12780 solver.cpp:219] Iteration 36 (0.415165 iter/s, 2.40868s/1 iters), loss = 16234.1
I0507 12:13:59.880189 12780 solver.cpp:238]     Train net output #0: loss = 2143.07 (* 1 = 2143.07 loss)
I0507 12:13:59.880189 12780 sgd_solver.cpp:105] Iteration 36, lr = 0.005
I0507 12:14:02.280844 12780 solver.cpp:219] Iteration 37 (0.416695 iter/s, 2.39983s/1 iters), loss = 16287.8
I0507 12:14:02.281846 12780 solver.cpp:238]     Train net output #0: loss = 1783.89 (* 1 = 1783.89 loss)
I0507 12:14:02.281846 12780 sgd_solver.cpp:105] Iteration 37, lr = 0.005
I0507 12:14:04.720722 12780 solver.cpp:219] Iteration 38 (0.409231 iter/s, 2.44361s/1 iters), loss = 20617.1
I0507 12:14:04.720722 12780 solver.cpp:238]     Train net output #0: loss = 1357.1 (* 1 = 1357.1 loss)
I0507 12:14:04.720722 12780 sgd_solver.cpp:105] Iteration 38, lr = 0.005
I0507 12:14:09.534754 12780 solver.cpp:219] Iteration 39 (0.207691 iter/s, 4.81484s/1 iters), loss = 16831.4
I0507 12:14:09.534754 12780 solver.cpp:238]     Train net output #0: loss = 3215.97 (* 1 = 3215.97 loss)
I0507 12:14:09.534754 12780 sgd_solver.cpp:105] Iteration 39, lr = 0.005
I0507 12:14:12.019812 12780 solver.cpp:219] Iteration 40 (0.404163 iter/s, 2.47425s/1 iters), loss = 13949.8
I0507 12:14:12.019812 12780 solver.cpp:238]     Train net output #0: loss = 1387.47 (* 1 = 1387.47 loss)
I0507 12:14:12.020813 12780 sgd_solver.cpp:105] Iteration 40, lr = 0.005
I0507 12:14:14.356256 12780 solver.cpp:219] Iteration 41 (0.42583 iter/s, 2.34836s/1 iters), loss = 14166.8
I0507 12:14:14.356256 12780 solver.cpp:238]     Train net output #0: loss = 1582.89 (* 1 = 1582.89 loss)
I0507 12:14:14.371858 12780 sgd_solver.cpp:105] Iteration 41, lr = 0.005
I0507 12:14:16.845984 12780 solver.cpp:219] Iteration 42 (0.402236 iter/s, 2.4861s/1 iters), loss = 20320.8
I0507 12:14:16.845984 12780 solver.cpp:238]     Train net output #0: loss = 3399.39 (* 1 = 3399.39 loss)
I0507 12:14:16.845984 12780 sgd_solver.cpp:105] Iteration 42, lr = 0.005
I0507 12:14:19.199713 12780 solver.cpp:219] Iteration 43 (0.424979 iter/s, 2.35306s/1 iters), loss = 17785.3
I0507 12:14:19.199713 12780 solver.cpp:238]     Train net output #0: loss = 19552.7 (* 1 = 19552.7 loss)
I0507 12:14:19.199713 12780 sgd_solver.cpp:105] Iteration 43, lr = 0.005
I0507 12:14:21.618798 12780 solver.cpp:219] Iteration 44 (0.415892 iter/s, 2.40447s/1 iters), loss = 13052.8
I0507 12:14:21.619804 12780 solver.cpp:238]     Train net output #0: loss = 7407.47 (* 1 = 7407.47 loss)
I0507 12:14:21.621801 12780 sgd_solver.cpp:105] Iteration 44, lr = 0.005
I0507 12:14:24.055761 12780 solver.cpp:219] Iteration 45 (0.410962 iter/s, 2.43331s/1 iters), loss = 17894.6
I0507 12:14:24.055761 12780 solver.cpp:238]     Train net output #0: loss = 3002.13 (* 1 = 3002.13 loss)
I0507 12:14:24.056761 12780 sgd_solver.cpp:105] Iteration 45, lr = 0.005
I0507 12:14:26.531208 12780 solver.cpp:219] Iteration 46 (0.404279 iter/s, 2.47354s/1 iters), loss = 19112.2
I0507 12:14:26.532208 12780 solver.cpp:238]     Train net output #0: loss = 12864.3 (* 1 = 12864.3 loss)
I0507 12:14:26.533206 12780 sgd_solver.cpp:105] Iteration 46, lr = 0.005
I0507 12:14:28.944772 12780 solver.cpp:219] Iteration 47 (0.412728 iter/s, 2.42291s/1 iters), loss = 7322.02
I0507 12:14:28.944772 12780 solver.cpp:238]     Train net output #0: loss = 5050.8 (* 1 = 5050.8 loss)
I0507 12:14:28.944772 12780 sgd_solver.cpp:105] Iteration 47, lr = 0.005
I0507 12:14:31.368352 12780 solver.cpp:219] Iteration 48 (0.413648 iter/s, 2.41751s/1 iters), loss = 15918.3
I0507 12:14:31.368352 12780 solver.cpp:238]     Train net output #0: loss = 5246.85 (* 1 = 5246.85 loss)
I0507 12:14:31.368352 12780 sgd_solver.cpp:105] Iteration 48, lr = 0.005
I0507 12:14:33.797804 12780 solver.cpp:219] Iteration 49 (0.410784 iter/s, 2.43437s/1 iters), loss = 21651.1
I0507 12:14:33.797804 12780 solver.cpp:238]     Train net output #0: loss = 7784 (* 1 = 7784 loss)
I0507 12:14:33.813429 12780 sgd_solver.cpp:105] Iteration 49, lr = 0.005
I0507 12:14:36.333366 12780 solver.cpp:219] Iteration 50 (0.395476 iter/s, 2.5286s/1 iters), loss = 14415.9
I0507 12:14:36.333366 12780 solver.cpp:238]     Train net output #0: loss = 13301.5 (* 1 = 13301.5 loss)
I0507 12:14:36.333366 12780 sgd_solver.cpp:105] Iteration 50, lr = 0.005
I0507 12:14:38.709487 12780 solver.cpp:219] Iteration 51 (0.421114 iter/s, 2.37465s/1 iters), loss = 17022.5
I0507 12:15:34.596482 12780 solver.cpp:238]     Train net output #0: loss = 4936.6 (* 1 = 4936.6 loss)
I0507 12:15:34.596482 12780 sgd_solver.cpp:105] Iteration 51, lr = 0.005

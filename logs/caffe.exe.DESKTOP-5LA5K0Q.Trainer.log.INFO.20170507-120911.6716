Log file created at: 2017/05/07 12:09:11
Running on machine: DESKTOP-5LA5K0Q
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0507 12:09:11.955688  6964 caffe.cpp:219] Using GPUs 0
I0507 12:09:12.190065  6964 caffe.cpp:224] GPU 0: TITAN X (Pascal)
I0507 12:09:12.794481  6964 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 12:09:12.810106  6964 solver.cpp:44] Initializing solver from parameters: 
test_iter: 38
test_interval: 100
base_lr: 0.0005
display: 1
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 800
snapshot_prefix: "examples/Depth_estimation_basedLiu/models/Model_"
solver_mode: GPU
device_id: 0
net: "examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt"
train_state {
  level: 0
  stage: ""
}
average_loss: 1
iter_size: 19
I0507 12:09:12.810106  6964 solver.cpp:87] Creating training net from net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 12:09:12.810106  6964 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0507 12:09:12.810106  6964 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/train.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 12:09:12.810106  6964 layer_factory.cpp:58] Creating layer data
I0507 12:09:12.810106  6964 net.cpp:84] Creating Layer data
I0507 12:09:12.810106  6964 net.cpp:380] data -> data
I0507 12:09:12.810106  6964 net.cpp:380] data -> label
I0507 12:09:12.810106  6964 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/train.txt
I0507 12:09:12.810106  6964 hdf5_data_layer.cpp:94] Number of HDF5 files: 17
I0507 12:09:12.810106  6964 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0507 12:09:14.024638  6964 net.cpp:122] Setting up data
I0507 12:09:14.024638  6964 net.cpp:129] Top shape: 50 3 112 112 (1881600)
I0507 12:09:14.024638  6964 net.cpp:129] Top shape: 50 1 (50)
I0507 12:09:14.024638  6964 net.cpp:137] Memory required for data: 7526600
I0507 12:09:14.024638  6964 layer_factory.cpp:58] Creating layer conv1
I0507 12:09:14.024638  6964 net.cpp:84] Creating Layer conv1
I0507 12:09:14.024638  6964 net.cpp:406] conv1 <- data
I0507 12:09:14.024638  6964 net.cpp:380] conv1 -> conv1
I0507 12:09:14.665271  6964 net.cpp:122] Setting up conv1
I0507 12:09:14.665271  6964 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 12:09:14.665271  6964 net.cpp:137] Memory required for data: 168089800
I0507 12:09:14.665271  6964 layer_factory.cpp:58] Creating layer relu1
I0507 12:09:14.665271  6964 net.cpp:84] Creating Layer relu1
I0507 12:09:14.665271  6964 net.cpp:406] relu1 <- conv1
I0507 12:09:14.665271  6964 net.cpp:367] relu1 -> conv1 (in-place)
I0507 12:09:14.665271  6964 net.cpp:122] Setting up relu1
I0507 12:09:14.665271  6964 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 12:09:14.665271  6964 net.cpp:137] Memory required for data: 328653000
I0507 12:09:14.665271  6964 layer_factory.cpp:58] Creating layer pool1
I0507 12:09:14.665271  6964 net.cpp:84] Creating Layer pool1
I0507 12:09:14.665271  6964 net.cpp:406] pool1 <- conv1
I0507 12:09:14.665271  6964 net.cpp:380] pool1 -> pool1
I0507 12:09:14.665271  6964 net.cpp:122] Setting up pool1
I0507 12:09:14.665271  6964 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0507 12:09:14.665271  6964 net.cpp:137] Memory required for data: 368793800
I0507 12:09:14.665271  6964 layer_factory.cpp:58] Creating layer conv2
I0507 12:09:14.665271  6964 net.cpp:84] Creating Layer conv2
I0507 12:09:14.665271  6964 net.cpp:406] conv2 <- pool1
I0507 12:09:14.665271  6964 net.cpp:380] conv2 -> conv2
I0507 12:09:14.680896  6964 net.cpp:122] Setting up conv2
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 529357000
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer relu2
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer relu2
I0507 12:09:14.680896  6964 net.cpp:406] relu2 <- conv2
I0507 12:09:14.680896  6964 net.cpp:367] relu2 -> conv2 (in-place)
I0507 12:09:14.680896  6964 net.cpp:122] Setting up relu2
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 689920200
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer pool2
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer pool2
I0507 12:09:14.680896  6964 net.cpp:406] pool2 <- conv2
I0507 12:09:14.680896  6964 net.cpp:380] pool2 -> pool2
I0507 12:09:14.680896  6964 net.cpp:122] Setting up pool2
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 730061000
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer conv3
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer conv3
I0507 12:09:14.680896  6964 net.cpp:406] conv3 <- pool2
I0507 12:09:14.680896  6964 net.cpp:380] conv3 -> conv3
I0507 12:09:14.680896  6964 net.cpp:122] Setting up conv3
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 770201800
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer relu3
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer relu3
I0507 12:09:14.680896  6964 net.cpp:406] relu3 <- conv3
I0507 12:09:14.680896  6964 net.cpp:367] relu3 -> conv3 (in-place)
I0507 12:09:14.680896  6964 net.cpp:122] Setting up relu3
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 810342600
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer conv4
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer conv4
I0507 12:09:14.680896  6964 net.cpp:406] conv4 <- conv3
I0507 12:09:14.680896  6964 net.cpp:380] conv4 -> conv4
I0507 12:09:14.680896  6964 net.cpp:122] Setting up conv4
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 850483400
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer relu4
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer relu4
I0507 12:09:14.680896  6964 net.cpp:406] relu4 <- conv4
I0507 12:09:14.680896  6964 net.cpp:367] relu4 -> conv4 (in-place)
I0507 12:09:14.680896  6964 net.cpp:122] Setting up relu4
I0507 12:09:14.680896  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.680896  6964 net.cpp:137] Memory required for data: 890624200
I0507 12:09:14.680896  6964 layer_factory.cpp:58] Creating layer conv5
I0507 12:09:14.680896  6964 net.cpp:84] Creating Layer conv5
I0507 12:09:14.680896  6964 net.cpp:406] conv5 <- conv4
I0507 12:09:14.680896  6964 net.cpp:380] conv5 -> conv5
I0507 12:09:14.696521  6964 net.cpp:122] Setting up conv5
I0507 12:09:14.696521  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.696521  6964 net.cpp:137] Memory required for data: 930765000
I0507 12:09:14.696521  6964 layer_factory.cpp:58] Creating layer relu5
I0507 12:09:14.696521  6964 net.cpp:84] Creating Layer relu5
I0507 12:09:14.696521  6964 net.cpp:406] relu5 <- conv5
I0507 12:09:14.696521  6964 net.cpp:367] relu5 -> conv5 (in-place)
I0507 12:09:14.696521  6964 net.cpp:122] Setting up relu5
I0507 12:09:14.696521  6964 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 12:09:14.696521  6964 net.cpp:137] Memory required for data: 970905800
I0507 12:09:14.696521  6964 layer_factory.cpp:58] Creating layer pool3
I0507 12:09:14.696521  6964 net.cpp:84] Creating Layer pool3
I0507 12:09:14.696521  6964 net.cpp:406] pool3 <- conv5
I0507 12:09:14.696521  6964 net.cpp:380] pool3 -> pool3
I0507 12:09:14.696521  6964 net.cpp:122] Setting up pool3
I0507 12:09:14.696521  6964 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0507 12:09:14.696521  6964 net.cpp:137] Memory required for data: 980941000
I0507 12:09:14.696521  6964 layer_factory.cpp:58] Creating layer fc6
I0507 12:09:14.696521  6964 net.cpp:84] Creating Layer fc6
I0507 12:09:14.696521  6964 net.cpp:406] fc6 <- pool3
I0507 12:09:14.696521  6964 net.cpp:380] fc6 -> fc6
I0507 12:09:15.102777  6964 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 12:09:17.500784  6964 net.cpp:122] Setting up fc6
I0507 12:09:17.500784  6964 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:09:17.500784  6964 net.cpp:137] Memory required for data: 981760200
I0507 12:09:17.500784  6964 layer_factory.cpp:58] Creating layer relu6
I0507 12:09:17.500784  6964 net.cpp:84] Creating Layer relu6
I0507 12:09:17.500784  6964 net.cpp:406] relu6 <- fc6
I0507 12:09:17.500784  6964 net.cpp:367] relu6 -> fc6 (in-place)
I0507 12:09:17.500784  6964 net.cpp:122] Setting up relu6
I0507 12:09:17.500784  6964 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:09:17.500784  6964 net.cpp:137] Memory required for data: 982579400
I0507 12:09:17.500784  6964 layer_factory.cpp:58] Creating layer drop6
I0507 12:09:17.500784  6964 net.cpp:84] Creating Layer drop6
I0507 12:09:17.500784  6964 net.cpp:406] drop6 <- fc6
I0507 12:09:17.500784  6964 net.cpp:367] drop6 -> fc6 (in-place)
I0507 12:09:17.500784  6964 net.cpp:122] Setting up drop6
I0507 12:09:17.500784  6964 net.cpp:129] Top shape: 50 4096 (204800)
I0507 12:09:17.500784  6964 net.cpp:137] Memory required for data: 983398600
I0507 12:09:17.500784  6964 layer_factory.cpp:58] Creating layer fc7
I0507 12:09:17.500784  6964 net.cpp:84] Creating Layer fc7
I0507 12:09:17.500784  6964 net.cpp:406] fc7 <- fc6
I0507 12:09:17.500784  6964 net.cpp:380] fc7 -> fc7
I0507 12:09:17.516409  6964 net.cpp:122] Setting up fc7
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: 50 128 (6400)
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983424200
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer relu7
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer relu7
I0507 12:09:17.516409  6964 net.cpp:406] relu7 <- fc7
I0507 12:09:17.516409  6964 net.cpp:367] relu7 -> fc7 (in-place)
I0507 12:09:17.516409  6964 net.cpp:122] Setting up relu7
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: 50 128 (6400)
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983449800
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer fc8
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer fc8
I0507 12:09:17.516409  6964 net.cpp:406] fc8 <- fc7
I0507 12:09:17.516409  6964 net.cpp:380] fc8 -> fc8
I0507 12:09:17.516409  6964 net.cpp:122] Setting up fc8
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: 50 16 (800)
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983453000
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer sig8
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer sig8
I0507 12:09:17.516409  6964 net.cpp:406] sig8 <- fc8
I0507 12:09:17.516409  6964 net.cpp:367] sig8 -> fc8 (in-place)
I0507 12:09:17.516409  6964 net.cpp:122] Setting up sig8
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: 50 16 (800)
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983456200
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer fc9
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer fc9
I0507 12:09:17.516409  6964 net.cpp:406] fc9 <- fc8
I0507 12:09:17.516409  6964 net.cpp:380] fc9 -> fc9
I0507 12:09:17.516409  6964 net.cpp:122] Setting up fc9
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: 50 1 (50)
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983456400
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer loss
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer loss
I0507 12:09:17.516409  6964 net.cpp:406] loss <- fc9
I0507 12:09:17.516409  6964 net.cpp:406] loss <- label
I0507 12:09:17.516409  6964 net.cpp:380] loss -> loss
I0507 12:09:17.516409  6964 net.cpp:122] Setting up loss
I0507 12:09:17.516409  6964 net.cpp:129] Top shape: (1)
I0507 12:09:17.516409  6964 net.cpp:132]     with loss weight 1
I0507 12:09:17.516409  6964 net.cpp:137] Memory required for data: 983456404
I0507 12:09:17.516409  6964 net.cpp:198] loss needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] fc9 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] sig8 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] fc8 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu7 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] fc7 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] drop6 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu6 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] fc6 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] pool3 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu5 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] conv5 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu4 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] conv4 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu3 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] conv3 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] pool2 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu2 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] conv2 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] pool1 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] relu1 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:198] conv1 needs backward computation.
I0507 12:09:17.516409  6964 net.cpp:200] data does not need backward computation.
I0507 12:09:17.516409  6964 net.cpp:242] This network produces output loss
I0507 12:09:17.516409  6964 net.cpp:255] Network initialization done.
I0507 12:09:17.516409  6964 solver.cpp:173] Creating test net (#0) specified by net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 12:09:17.516409  6964 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0507 12:09:17.516409  6964 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/test.txt"
    batch_size: 25
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 12:09:17.516409  6964 layer_factory.cpp:58] Creating layer data
I0507 12:09:17.516409  6964 net.cpp:84] Creating Layer data
I0507 12:09:17.516409  6964 net.cpp:380] data -> data
I0507 12:09:17.516409  6964 net.cpp:380] data -> label
I0507 12:09:17.516409  6964 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/test.txt
I0507 12:09:17.516409  6964 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0507 12:09:19.563325  6964 net.cpp:122] Setting up data
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 3 112 112 (940800)
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 1 (25)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 3763300
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer conv1
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer conv1
I0507 12:09:19.563325  6964 net.cpp:406] conv1 <- data
I0507 12:09:19.563325  6964 net.cpp:380] conv1 -> conv1
I0507 12:09:19.563325  6964 net.cpp:122] Setting up conv1
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 64 112 112 (20070400)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 84044900
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer relu1
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer relu1
I0507 12:09:19.563325  6964 net.cpp:406] relu1 <- conv1
I0507 12:09:19.563325  6964 net.cpp:367] relu1 -> conv1 (in-place)
I0507 12:09:19.563325  6964 net.cpp:122] Setting up relu1
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 64 112 112 (20070400)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 164326500
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer pool1
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer pool1
I0507 12:09:19.563325  6964 net.cpp:406] pool1 <- conv1
I0507 12:09:19.563325  6964 net.cpp:380] pool1 -> pool1
I0507 12:09:19.563325  6964 net.cpp:122] Setting up pool1
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 184396900
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer conv2
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer conv2
I0507 12:09:19.563325  6964 net.cpp:406] conv2 <- pool1
I0507 12:09:19.563325  6964 net.cpp:380] conv2 -> conv2
I0507 12:09:19.563325  6964 net.cpp:122] Setting up conv2
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 264678500
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer relu2
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer relu2
I0507 12:09:19.563325  6964 net.cpp:406] relu2 <- conv2
I0507 12:09:19.563325  6964 net.cpp:367] relu2 -> conv2 (in-place)
I0507 12:09:19.563325  6964 net.cpp:122] Setting up relu2
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 256 56 56 (20070400)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 344960100
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer pool2
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer pool2
I0507 12:09:19.563325  6964 net.cpp:406] pool2 <- conv2
I0507 12:09:19.563325  6964 net.cpp:380] pool2 -> pool2
I0507 12:09:19.563325  6964 net.cpp:122] Setting up pool2
I0507 12:09:19.563325  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.563325  6964 net.cpp:137] Memory required for data: 365030500
I0507 12:09:19.563325  6964 layer_factory.cpp:58] Creating layer conv3
I0507 12:09:19.563325  6964 net.cpp:84] Creating Layer conv3
I0507 12:09:19.563325  6964 net.cpp:406] conv3 <- pool2
I0507 12:09:19.563325  6964 net.cpp:380] conv3 -> conv3
I0507 12:09:19.578961  6964 net.cpp:122] Setting up conv3
I0507 12:09:19.578961  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.578961  6964 net.cpp:137] Memory required for data: 385100900
I0507 12:09:19.578961  6964 layer_factory.cpp:58] Creating layer relu3
I0507 12:09:19.578961  6964 net.cpp:84] Creating Layer relu3
I0507 12:09:19.578961  6964 net.cpp:406] relu3 <- conv3
I0507 12:09:19.578961  6964 net.cpp:367] relu3 -> conv3 (in-place)
I0507 12:09:19.578961  6964 net.cpp:122] Setting up relu3
I0507 12:09:19.578961  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.578961  6964 net.cpp:137] Memory required for data: 405171300
I0507 12:09:19.578961  6964 layer_factory.cpp:58] Creating layer conv4
I0507 12:09:19.578961  6964 net.cpp:84] Creating Layer conv4
I0507 12:09:19.578961  6964 net.cpp:406] conv4 <- conv3
I0507 12:09:19.578961  6964 net.cpp:380] conv4 -> conv4
I0507 12:09:19.594586  6964 net.cpp:122] Setting up conv4
I0507 12:09:19.594586  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.594586  6964 net.cpp:137] Memory required for data: 425241700
I0507 12:09:19.594586  6964 layer_factory.cpp:58] Creating layer relu4
I0507 12:09:19.594586  6964 net.cpp:84] Creating Layer relu4
I0507 12:09:19.594586  6964 net.cpp:406] relu4 <- conv4
I0507 12:09:19.594586  6964 net.cpp:367] relu4 -> conv4 (in-place)
I0507 12:09:19.594586  6964 net.cpp:122] Setting up relu4
I0507 12:09:19.594586  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.594586  6964 net.cpp:137] Memory required for data: 445312100
I0507 12:09:19.594586  6964 layer_factory.cpp:58] Creating layer conv5
I0507 12:09:19.594586  6964 net.cpp:84] Creating Layer conv5
I0507 12:09:19.594586  6964 net.cpp:406] conv5 <- conv4
I0507 12:09:19.594586  6964 net.cpp:380] conv5 -> conv5
I0507 12:09:19.594586  6964 net.cpp:122] Setting up conv5
I0507 12:09:19.594586  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.594586  6964 net.cpp:137] Memory required for data: 465382500
I0507 12:09:19.594586  6964 layer_factory.cpp:58] Creating layer relu5
I0507 12:09:19.594586  6964 net.cpp:84] Creating Layer relu5
I0507 12:09:19.594586  6964 net.cpp:406] relu5 <- conv5
I0507 12:09:19.594586  6964 net.cpp:367] relu5 -> conv5 (in-place)
I0507 12:09:19.594586  6964 net.cpp:122] Setting up relu5
I0507 12:09:19.594586  6964 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0507 12:09:19.594586  6964 net.cpp:137] Memory required for data: 485452900
I0507 12:09:19.594586  6964 layer_factory.cpp:58] Creating layer pool3
I0507 12:09:19.594586  6964 net.cpp:84] Creating Layer pool3
I0507 12:09:19.594586  6964 net.cpp:406] pool3 <- conv5
I0507 12:09:19.594586  6964 net.cpp:380] pool3 -> pool3
I0507 12:09:19.594586  6964 net.cpp:122] Setting up pool3
I0507 12:09:19.594586  6964 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0507 12:09:19.594586  6964 net.cpp:137] Memory required for data: 490470500
I0507 12:09:19.594586  6964 layer_factory.cpp:58] Creating layer fc6
I0507 12:09:19.594586  6964 net.cpp:84] Creating Layer fc6
I0507 12:09:19.594586  6964 net.cpp:406] fc6 <- pool3
I0507 12:09:19.594586  6964 net.cpp:380] fc6 -> fc6
I0507 12:09:22.553998  6964 net.cpp:122] Setting up fc6
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 490880100
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer relu6
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer relu6
I0507 12:09:22.553998  6964 net.cpp:406] relu6 <- fc6
I0507 12:09:22.553998  6964 net.cpp:367] relu6 -> fc6 (in-place)
I0507 12:09:22.553998  6964 net.cpp:122] Setting up relu6
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491289700
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer drop6
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer drop6
I0507 12:09:22.553998  6964 net.cpp:406] drop6 <- fc6
I0507 12:09:22.553998  6964 net.cpp:367] drop6 -> fc6 (in-place)
I0507 12:09:22.553998  6964 net.cpp:122] Setting up drop6
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 4096 (102400)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491699300
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer fc7
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer fc7
I0507 12:09:22.553998  6964 net.cpp:406] fc7 <- fc6
I0507 12:09:22.553998  6964 net.cpp:380] fc7 -> fc7
I0507 12:09:22.553998  6964 net.cpp:122] Setting up fc7
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 128 (3200)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491712100
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer relu7
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer relu7
I0507 12:09:22.553998  6964 net.cpp:406] relu7 <- fc7
I0507 12:09:22.553998  6964 net.cpp:367] relu7 -> fc7 (in-place)
I0507 12:09:22.553998  6964 net.cpp:122] Setting up relu7
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 128 (3200)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491724900
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer fc8
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer fc8
I0507 12:09:22.553998  6964 net.cpp:406] fc8 <- fc7
I0507 12:09:22.553998  6964 net.cpp:380] fc8 -> fc8
I0507 12:09:22.553998  6964 net.cpp:122] Setting up fc8
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 16 (400)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491726500
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer sig8
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer sig8
I0507 12:09:22.553998  6964 net.cpp:406] sig8 <- fc8
I0507 12:09:22.553998  6964 net.cpp:367] sig8 -> fc8 (in-place)
I0507 12:09:22.553998  6964 net.cpp:122] Setting up sig8
I0507 12:09:22.553998  6964 net.cpp:129] Top shape: 25 16 (400)
I0507 12:09:22.553998  6964 net.cpp:137] Memory required for data: 491728100
I0507 12:09:22.553998  6964 layer_factory.cpp:58] Creating layer fc9
I0507 12:09:22.553998  6964 net.cpp:84] Creating Layer fc9
I0507 12:09:22.553998  6964 net.cpp:406] fc9 <- fc8
I0507 12:09:22.553998  6964 net.cpp:380] fc9 -> fc9
I0507 12:09:22.569623  6964 net.cpp:122] Setting up fc9
I0507 12:09:22.569623  6964 net.cpp:129] Top shape: 25 1 (25)
I0507 12:09:22.569623  6964 net.cpp:137] Memory required for data: 491728200
I0507 12:09:22.569623  6964 layer_factory.cpp:58] Creating layer loss
I0507 12:09:22.569623  6964 net.cpp:84] Creating Layer loss
I0507 12:09:22.569623  6964 net.cpp:406] loss <- fc9
I0507 12:09:22.569623  6964 net.cpp:406] loss <- label
I0507 12:09:22.569623  6964 net.cpp:380] loss -> loss
I0507 12:09:22.569623  6964 net.cpp:122] Setting up loss
I0507 12:09:22.569623  6964 net.cpp:129] Top shape: (1)
I0507 12:09:22.569623  6964 net.cpp:132]     with loss weight 1
I0507 12:09:22.569623  6964 net.cpp:137] Memory required for data: 491728204
I0507 12:09:22.569623  6964 net.cpp:198] loss needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] fc9 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] sig8 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] fc8 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu7 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] fc7 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] drop6 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu6 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] fc6 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] pool3 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu5 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] conv5 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu4 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] conv4 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu3 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] conv3 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] pool2 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu2 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] conv2 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] pool1 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] relu1 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:198] conv1 needs backward computation.
I0507 12:09:22.569623  6964 net.cpp:200] data does not need backward computation.
I0507 12:09:22.569623  6964 net.cpp:242] This network produces output loss
I0507 12:09:22.569623  6964 net.cpp:255] Network initialization done.
I0507 12:09:22.569623  6964 solver.cpp:56] Solver scaffolding done.
I0507 12:09:22.569623  6964 caffe.cpp:249] Starting Optimization
I0507 12:09:22.569623  6964 solver.cpp:273] Solving DepthEstimation
I0507 12:09:22.569623  6964 solver.cpp:274] Learning Rate Policy: fixed
I0507 12:09:22.600877  6964 solver.cpp:331] Iteration 0, Testing net (#0)
I0507 12:09:24.030256  6964 solver.cpp:398]     Test net output #0: loss = 18961.7 (* 1 = 18961.7 loss)
I0507 12:09:26.321348  6964 solver.cpp:219] Iteration 0 (-1.96082e-38 iter/s, 3.72987s/1 iters), loss = 22701.4
I0507 12:09:26.321348  6964 solver.cpp:238]     Train net output #0: loss = 107.661 (* 1 = 107.661 loss)
I0507 12:09:26.321348  6964 sgd_solver.cpp:105] Iteration 0, lr = 0.0005
I0507 12:09:28.604411  6964 solver.cpp:219] Iteration 1 (0.440401 iter/s, 2.27066s/1 iters), loss = 15666.5
I0507 12:09:28.604411  6964 solver.cpp:238]     Train net output #0: loss = 10060.5 (* 1 = 10060.5 loss)
I0507 12:09:28.604411  6964 sgd_solver.cpp:105] Iteration 1, lr = 0.0005
I0507 12:09:30.887365  6964 solver.cpp:219] Iteration 2 (0.437148 iter/s, 2.28756s/1 iters), loss = 17016.1
I0507 12:09:30.887365  6964 solver.cpp:238]     Train net output #0: loss = 208.113 (* 1 = 208.113 loss)
I0507 12:09:30.887365  6964 sgd_solver.cpp:105] Iteration 2, lr = 0.0005
I0507 12:09:33.163214  6964 solver.cpp:219] Iteration 3 (0.440055 iter/s, 2.27244s/1 iters), loss = 25130.6
I0507 12:09:33.163214  6964 solver.cpp:238]     Train net output #0: loss = 159.07 (* 1 = 159.07 loss)
I0507 12:09:33.163214  6964 sgd_solver.cpp:105] Iteration 3, lr = 0.0005
I0507 12:09:35.428858  6964 solver.cpp:219] Iteration 4 (0.441474 iter/s, 2.26514s/1 iters), loss = 24365.6
I0507 12:09:35.428858  6964 solver.cpp:238]     Train net output #0: loss = 44.3553 (* 1 = 44.3553 loss)
I0507 12:09:35.428858  6964 sgd_solver.cpp:105] Iteration 4, lr = 0.0005
I0507 12:09:37.680660  6964 solver.cpp:219] Iteration 5 (0.444218 iter/s, 2.25115s/1 iters), loss = 17434.4
I0507 12:09:37.680660  6964 solver.cpp:238]     Train net output #0: loss = 32.1832 (* 1 = 32.1832 loss)
I0507 12:09:37.680660  6964 sgd_solver.cpp:105] Iteration 5, lr = 0.0005
I0507 12:09:39.946107  6964 solver.cpp:219] Iteration 6 (0.443481 iter/s, 2.25489s/1 iters), loss = 22916.6
I0507 12:09:39.946107  6964 solver.cpp:238]     Train net output #0: loss = 16.0384 (* 1 = 16.0384 loss)
I0507 12:09:39.946107  6964 sgd_solver.cpp:105] Iteration 6, lr = 0.0005
I0507 12:09:42.204607  6964 solver.cpp:219] Iteration 7 (0.441701 iter/s, 2.26398s/1 iters), loss = 12625.2
I0507 12:09:42.204607  6964 solver.cpp:238]     Train net output #0: loss = 12.879 (* 1 = 12.879 loss)
I0507 12:09:42.204607  6964 sgd_solver.cpp:105] Iteration 7, lr = 0.0005
I0507 12:09:44.472887  6964 solver.cpp:219] Iteration 8 (0.440545 iter/s, 2.26991s/1 iters), loss = 23875.4
I0507 12:09:44.472887  6964 solver.cpp:238]     Train net output #0: loss = 22.9528 (* 1 = 22.9528 loss)
I0507 12:09:44.472887  6964 sgd_solver.cpp:105] Iteration 8, lr = 0.0005
I0507 12:09:48.389904  6964 solver.cpp:219] Iteration 9 (0.255931 iter/s, 3.9073s/1 iters), loss = 20737.1
I0507 12:09:48.389904  6964 solver.cpp:238]     Train net output #0: loss = 6.62968 (* 1 = 6.62968 loss)
I0507 12:09:48.389904  6964 sgd_solver.cpp:105] Iteration 9, lr = 0.0005
I0507 12:09:50.670586  6964 solver.cpp:219] Iteration 10 (0.437103 iter/s, 2.28779s/1 iters), loss = 15649
I0507 12:09:50.670586  6964 solver.cpp:238]     Train net output #0: loss = 8.6635 (* 1 = 8.6635 loss)
I0507 12:09:50.670586  6964 sgd_solver.cpp:105] Iteration 10, lr = 0.0005
I0507 12:09:52.954615  6964 solver.cpp:219] Iteration 11 (0.439622 iter/s, 2.27468s/1 iters), loss = 18968.5
I0507 12:09:52.954615  6964 solver.cpp:238]     Train net output #0: loss = 27.7115 (* 1 = 27.7115 loss)
I0507 12:09:52.954615  6964 sgd_solver.cpp:105] Iteration 11, lr = 0.0005
I0507 12:09:55.234542  6964 solver.cpp:219] Iteration 12 (0.43899 iter/s, 2.27796s/1 iters), loss = 25510.8
I0507 12:09:55.234542  6964 solver.cpp:238]     Train net output #0: loss = 21355.9 (* 1 = 21355.9 loss)
I0507 12:09:55.234542  6964 sgd_solver.cpp:105] Iteration 12, lr = 0.0005
I0507 12:09:57.517401  6964 solver.cpp:219] Iteration 13 (0.438772 iter/s, 2.27909s/1 iters), loss = 13293.7
I0507 12:09:57.517401  6964 solver.cpp:238]     Train net output #0: loss = 29.4931 (* 1 = 29.4931 loss)
I0507 12:09:57.517401  6964 sgd_solver.cpp:105] Iteration 13, lr = 0.0005
I0507 12:09:59.798681  6964 solver.cpp:219] Iteration 14 (0.439143 iter/s, 2.27716s/1 iters), loss = 11971.1
I0507 12:09:59.798681  6964 solver.cpp:238]     Train net output #0: loss = 70.8867 (* 1 = 70.8867 loss)
I0507 12:09:59.798681  6964 sgd_solver.cpp:105] Iteration 14, lr = 0.0005
I0507 12:10:02.081599  6964 solver.cpp:219] Iteration 15 (0.437052 iter/s, 2.28806s/1 iters), loss = 22782.9
I0507 12:10:02.081599  6964 solver.cpp:238]     Train net output #0: loss = 11616 (* 1 = 11616 loss)
I0507 12:10:02.081599  6964 sgd_solver.cpp:105] Iteration 15, lr = 0.0005
I0507 12:10:04.364604  6964 solver.cpp:219] Iteration 16 (0.437772 iter/s, 2.28429s/1 iters), loss = 18971.7
I0507 12:10:04.364604  6964 solver.cpp:238]     Train net output #0: loss = 93.3313 (* 1 = 93.3313 loss)
I0507 12:10:04.364604  6964 sgd_solver.cpp:105] Iteration 16, lr = 0.0005
I0507 12:10:06.655428  6964 solver.cpp:219] Iteration 17 (0.437451 iter/s, 2.28597s/1 iters), loss = 17101.5
I0507 12:10:06.655428  6964 solver.cpp:238]     Train net output #0: loss = 96.1813 (* 1 = 96.1813 loss)
I0507 12:10:06.655428  6964 sgd_solver.cpp:105] Iteration 17, lr = 0.0005
I0507 12:10:08.952330  6964 solver.cpp:219] Iteration 18 (0.436222 iter/s, 2.29241s/1 iters), loss = 15423
I0507 12:10:08.952330  6964 solver.cpp:238]     Train net output #0: loss = 2388.76 (* 1 = 2388.76 loss)
I0507 12:10:08.952330  6964 sgd_solver.cpp:105] Iteration 18, lr = 0.0005
I0507 12:10:12.937093  6964 solver.cpp:219] Iteration 19 (0.251187 iter/s, 3.98109s/1 iters), loss = 16562.9
I0507 12:10:12.937093  6964 solver.cpp:238]     Train net output #0: loss = 252.012 (* 1 = 252.012 loss)
I0507 12:10:12.937093  6964 sgd_solver.cpp:105] Iteration 19, lr = 0.0005
I0507 12:10:15.262359  6964 solver.cpp:219] Iteration 20 (0.4309 iter/s, 2.32072s/1 iters), loss = 13528.1
I0507 12:10:15.262359  6964 solver.cpp:238]     Train net output #0: loss = 323.563 (* 1 = 323.563 loss)
I0507 12:10:15.262359  6964 sgd_solver.cpp:105] Iteration 20, lr = 0.0005
I0507 12:10:17.616286  6964 solver.cpp:219] Iteration 21 (0.423625 iter/s, 2.36058s/1 iters), loss = 14327.2
I0507 12:10:17.616286  6964 solver.cpp:238]     Train net output #0: loss = 442.851 (* 1 = 442.851 loss)
I0507 12:10:17.616286  6964 sgd_solver.cpp:105] Iteration 21, lr = 0.0005
I0507 12:10:20.055562  6964 solver.cpp:219] Iteration 22 (0.411374 iter/s, 2.43088s/1 iters), loss = 19824.2
I0507 12:10:20.055562  6964 solver.cpp:238]     Train net output #0: loss = 13021.5 (* 1 = 13021.5 loss)
I0507 12:10:20.055562  6964 sgd_solver.cpp:105] Iteration 22, lr = 0.0005
I0507 12:10:22.385340  6964 solver.cpp:219] Iteration 23 (0.427402 iter/s, 2.33972s/1 iters), loss = 16993
I0507 12:10:22.385340  6964 solver.cpp:238]     Train net output #0: loss = 17179.5 (* 1 = 17179.5 loss)
I0507 12:10:22.385340  6964 sgd_solver.cpp:105] Iteration 23, lr = 0.0005
I0507 12:10:24.763106  6964 solver.cpp:219] Iteration 24 (0.42334 iter/s, 2.36217s/1 iters), loss = 16005.5
I0507 12:10:24.763106  6964 solver.cpp:238]     Train net output #0: loss = 4731.72 (* 1 = 4731.72 loss)
I0507 12:10:24.764221  6964 sgd_solver.cpp:105] Iteration 24, lr = 0.0005
I0507 12:10:27.217571  6964 solver.cpp:219] Iteration 25 (0.407199 iter/s, 2.4558s/1 iters), loss = 20470.3
I0507 12:10:27.217571  6964 solver.cpp:238]     Train net output #0: loss = 717.198 (* 1 = 717.198 loss)
I0507 12:10:27.217571  6964 sgd_solver.cpp:105] Iteration 25, lr = 0.0005
I0507 12:10:29.576975  6964 solver.cpp:219] Iteration 26 (0.423415 iter/s, 2.36175s/1 iters), loss = 9320.5
I0507 12:10:29.576975  6964 solver.cpp:238]     Train net output #0: loss = 1091.61 (* 1 = 1091.61 loss)
I0507 12:10:29.576975  6964 sgd_solver.cpp:105] Iteration 26, lr = 0.0005
I0507 12:10:31.985011  6964 solver.cpp:219] Iteration 27 (0.415487 iter/s, 2.40681s/1 iters), loss = 10579
I0507 12:10:31.985011  6964 solver.cpp:238]     Train net output #0: loss = 1330.43 (* 1 = 1330.43 loss)
I0507 12:10:31.985011  6964 sgd_solver.cpp:105] Iteration 27, lr = 0.0005
I0507 12:10:34.471130  6964 solver.cpp:219] Iteration 28 (0.401671 iter/s, 2.4896s/1 iters), loss = 21948.9
I0507 12:10:34.471130  6964 solver.cpp:238]     Train net output #0: loss = 1469.89 (* 1 = 1469.89 loss)
I0507 12:10:34.471130  6964 sgd_solver.cpp:105] Iteration 28, lr = 0.0005
I0507 12:10:38.535311  6964 solver.cpp:219] Iteration 29 (0.246484 iter/s, 4.05706s/1 iters), loss = 15758.5
I0507 12:10:38.535311  6964 solver.cpp:238]     Train net output #0: loss = 1236.68 (* 1 = 1236.68 loss)
I0507 12:10:38.535311  6964 sgd_solver.cpp:105] Iteration 29, lr = 0.0005
I0507 12:10:41.171036  6964 solver.cpp:219] Iteration 30 (0.379288 iter/s, 2.63652s/1 iters), loss = 12442.1
I0507 12:10:41.171036  6964 solver.cpp:238]     Train net output #0: loss = 1807.8 (* 1 = 1807.8 loss)
I0507 12:10:41.171036  6964 sgd_solver.cpp:105] Iteration 30, lr = 0.0005
I0507 12:10:43.750159  6964 solver.cpp:219] Iteration 31 (0.389323 iter/s, 2.56856s/1 iters), loss = 10223
I0507 12:10:43.750159  6964 solver.cpp:238]     Train net output #0: loss = 1578.16 (* 1 = 1578.16 loss)
I0507 12:10:43.750159  6964 sgd_solver.cpp:105] Iteration 31, lr = 0.0005
I0507 12:10:46.265417  6964 solver.cpp:219] Iteration 32 (0.397409 iter/s, 2.5163s/1 iters), loss = 11114.1
I0507 12:10:46.265417  6964 solver.cpp:238]     Train net output #0: loss = 1964.67 (* 1 = 1964.67 loss)
I0507 12:10:46.265417  6964 sgd_solver.cpp:105] Iteration 32, lr = 0.0005
I0507 12:10:48.730244  6964 solver.cpp:219] Iteration 33 (0.406296 iter/s, 2.46126s/1 iters), loss = 17823.7
I0507 12:10:48.730244  6964 solver.cpp:238]     Train net output #0: loss = 5331 (* 1 = 5331 loss)
I0507 12:10:48.730244  6964 sgd_solver.cpp:105] Iteration 33, lr = 0.0005
I0507 12:10:51.278800  6964 solver.cpp:219] Iteration 34 (0.391258 iter/s, 2.55586s/1 iters), loss = 4853.68
I0507 12:10:51.278800  6964 solver.cpp:238]     Train net output #0: loss = 1863.3 (* 1 = 1863.3 loss)
I0507 12:10:51.278800  6964 sgd_solver.cpp:105] Iteration 34, lr = 0.0005
I0507 12:10:53.653825  6964 solver.cpp:219] Iteration 35 (0.42176 iter/s, 2.37101s/1 iters), loss = 1802.72
I0507 12:10:53.653825  6964 solver.cpp:238]     Train net output #0: loss = 1680.47 (* 1 = 1680.47 loss)
I0507 12:10:53.653825  6964 sgd_solver.cpp:105] Iteration 35, lr = 0.0005
I0507 12:10:56.047006  6964 solver.cpp:219] Iteration 36 (0.418599 iter/s, 2.38892s/1 iters), loss = 16200.8
I0507 12:10:56.047006  6964 solver.cpp:238]     Train net output #0: loss = 2311.68 (* 1 = 2311.68 loss)
I0507 12:10:56.047006  6964 sgd_solver.cpp:105] Iteration 36, lr = 0.0005
I0507 12:10:58.421715  6964 solver.cpp:219] Iteration 37 (0.421682 iter/s, 2.37146s/1 iters), loss = 16079
I0507 12:10:58.421715  6964 solver.cpp:238]     Train net output #0: loss = 2616.15 (* 1 = 2616.15 loss)
I0507 12:10:58.421715  6964 sgd_solver.cpp:105] Iteration 37, lr = 0.0005
I0507 12:11:00.845270  6964 solver.cpp:219] Iteration 38 (0.411587 iter/s, 2.42962s/1 iters), loss = 19780
I0507 12:11:00.845270  6964 solver.cpp:238]     Train net output #0: loss = 2582.87 (* 1 = 2582.87 loss)
I0507 12:11:00.845270  6964 sgd_solver.cpp:105] Iteration 38, lr = 0.0005
I0507 12:11:05.562433  6964 solver.cpp:219] Iteration 39 (0.212221 iter/s, 4.71207s/1 iters), loss = 16297.1
I0507 12:11:05.562433  6964 solver.cpp:238]     Train net output #0: loss = 4382.36 (* 1 = 4382.36 loss)
I0507 12:11:05.562433  6964 sgd_solver.cpp:105] Iteration 39, lr = 0.0005
I0507 12:11:08.062192  6964 solver.cpp:219] Iteration 40 (0.400018 iter/s, 2.49989s/1 iters), loss = 13829.4
I0507 12:11:08.062192  6964 solver.cpp:238]     Train net output #0: loss = 2758.47 (* 1 = 2758.47 loss)
I0507 12:11:08.062192  6964 sgd_solver.cpp:105] Iteration 40, lr = 0.0005
I0507 12:11:10.376852  6964 solver.cpp:219] Iteration 41 (0.432253 iter/s, 2.31346s/1 iters), loss = 14097.8
I0507 12:11:10.376852  6964 solver.cpp:238]     Train net output #0: loss = 2885.07 (* 1 = 2885.07 loss)
I0507 12:11:10.376852  6964 sgd_solver.cpp:105] Iteration 41, lr = 0.0005
I0507 12:11:12.722352  6964 solver.cpp:219] Iteration 42 (0.428603 iter/s, 2.33316s/1 iters), loss = 19672.4
I0507 12:11:12.722352  6964 solver.cpp:238]     Train net output #0: loss = 4280.77 (* 1 = 4280.77 loss)
I0507 12:11:12.722352  6964 sgd_solver.cpp:105] Iteration 42, lr = 0.0005
I0507 12:11:15.100936  6964 solver.cpp:219] Iteration 43 (0.419178 iter/s, 2.38562s/1 iters), loss = 17551.9
I0507 12:11:15.100936  6964 solver.cpp:238]     Train net output #0: loss = 19222.7 (* 1 = 19222.7 loss)
I0507 12:11:15.100936  6964 sgd_solver.cpp:105] Iteration 43, lr = 0.0005
I0507 12:11:17.590301  6964 solver.cpp:219] Iteration 44 (0.403545 iter/s, 2.47804s/1 iters), loss = 13070.9
I0507 12:11:17.590823  6964 solver.cpp:238]     Train net output #0: loss = 7510.8 (* 1 = 7510.8 loss)
I0507 12:11:17.592301  6964 sgd_solver.cpp:105] Iteration 44, lr = 0.0005
I0507 12:11:19.968466  6964 solver.cpp:219] Iteration 45 (0.419594 iter/s, 2.38326s/1 iters), loss = 17957.6
I0507 12:11:52.658413  6964 solver.cpp:238]     Train net output #0: loss = 2699.52 (* 1 = 2699.52 loss)
I0507 12:11:52.658413  6964 sgd_solver.cpp:105] Iteration 45, lr = 0.0005
I0507 12:11:54.970939  6964 solver.cpp:219] Iteration 46 (0.434513 iter/s, 2.30143s/1 iters), loss = 19321.3
I0507 12:11:54.970939  6964 solver.cpp:238]     Train net output #0: loss = 12626.8 (* 1 = 12626.8 loss)
I0507 12:11:54.970939  6964 sgd_solver.cpp:105] Iteration 46, lr = 0.0005
I0507 12:11:57.228523  6964 solver.cpp:219] Iteration 47 (0.443394 iter/s, 2.25533s/1 iters), loss = 6062.19
I0507 12:11:59.264292  6964 solver.cpp:238]     Train net output #0: loss = 3384.84 (* 1 = 3384.84 loss)
I0507 12:11:59.264292  6964 sgd_solver.cpp:105] Iteration 47, lr = 0.0005
I0507 12:12:01.547303  6964 solver.cpp:219] Iteration 48 (0.438129 iter/s, 2.28243s/1 iters), loss = 15683.4
I0507 12:12:01.547303  6964 solver.cpp:238]     Train net output #0: loss = 3507.6 (* 1 = 3507.6 loss)
I0507 12:12:01.562930  6964 sgd_solver.cpp:105] Iteration 48, lr = 0.0005

Log file created at: 2017/05/07 15:00:32
Running on machine: DESKTOP-5LA5K0Q
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0507 15:00:32.379199  5440 caffe.cpp:219] Using GPUs 0
I0507 15:00:32.660473  5440 caffe.cpp:224] GPU 0: TITAN X (Pascal)
I0507 15:00:33.259569  5440 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 15:00:33.290815  5440 solver.cpp:44] Initializing solver from parameters: 
test_iter: 38
test_interval: 100
base_lr: 0.0005
display: 1
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 800
snapshot_prefix: "examples/Depth_estimation_basedLiu/models/Model_"
solver_mode: GPU
device_id: 0
net: "examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt"
train_state {
  level: 0
  stage: ""
}
average_loss: 1
iter_size: 19
I0507 15:00:33.290815  5440 solver.cpp:87] Creating training net from net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 15:00:33.290815  5440 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0507 15:00:33.290815  5440 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/train.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 15:00:33.290815  5440 layer_factory.cpp:58] Creating layer data
I0507 15:00:33.290815  5440 net.cpp:84] Creating Layer data
I0507 15:00:33.290815  5440 net.cpp:380] data -> data
I0507 15:00:33.290815  5440 net.cpp:380] data -> label
I0507 15:00:33.290815  5440 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/train.txt
I0507 15:00:33.290815  5440 hdf5_data_layer.cpp:94] Number of HDF5 files: 17
I0507 15:00:33.290815  5440 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0507 15:00:34.525207  5440 net.cpp:122] Setting up data
I0507 15:00:34.525207  5440 net.cpp:129] Top shape: 50 3 112 112 (1881600)
I0507 15:00:34.525207  5440 net.cpp:129] Top shape: 50 1 (50)
I0507 15:00:34.525207  5440 net.cpp:137] Memory required for data: 7526600
I0507 15:00:34.525207  5440 layer_factory.cpp:58] Creating layer conv1
I0507 15:00:34.525207  5440 net.cpp:84] Creating Layer conv1
I0507 15:00:34.525207  5440 net.cpp:406] conv1 <- data
I0507 15:00:34.525207  5440 net.cpp:380] conv1 -> conv1
I0507 15:00:35.165839  5440 net.cpp:122] Setting up conv1
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 168089800
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer relu1
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer relu1
I0507 15:00:35.165839  5440 net.cpp:406] relu1 <- conv1
I0507 15:00:35.165839  5440 net.cpp:367] relu1 -> conv1 (in-place)
I0507 15:00:35.165839  5440 net.cpp:122] Setting up relu1
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 328653000
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer pool1
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer pool1
I0507 15:00:35.165839  5440 net.cpp:406] pool1 <- conv1
I0507 15:00:35.165839  5440 net.cpp:380] pool1 -> pool1
I0507 15:00:35.165839  5440 net.cpp:122] Setting up pool1
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 368793800
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer conv2
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer conv2
I0507 15:00:35.165839  5440 net.cpp:406] conv2 <- pool1
I0507 15:00:35.165839  5440 net.cpp:380] conv2 -> conv2
I0507 15:00:35.165839  5440 net.cpp:122] Setting up conv2
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 529357000
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer relu2
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer relu2
I0507 15:00:35.165839  5440 net.cpp:406] relu2 <- conv2
I0507 15:00:35.165839  5440 net.cpp:367] relu2 -> conv2 (in-place)
I0507 15:00:35.165839  5440 net.cpp:122] Setting up relu2
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 256 56 56 (40140800)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 689920200
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer pool2
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer pool2
I0507 15:00:35.165839  5440 net.cpp:406] pool2 <- conv2
I0507 15:00:35.165839  5440 net.cpp:380] pool2 -> pool2
I0507 15:00:35.165839  5440 net.cpp:122] Setting up pool2
I0507 15:00:35.165839  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.165839  5440 net.cpp:137] Memory required for data: 730061000
I0507 15:00:35.165839  5440 layer_factory.cpp:58] Creating layer conv3
I0507 15:00:35.165839  5440 net.cpp:84] Creating Layer conv3
I0507 15:00:35.165839  5440 net.cpp:406] conv3 <- pool2
I0507 15:00:35.165839  5440 net.cpp:380] conv3 -> conv3
I0507 15:00:35.181464  5440 net.cpp:122] Setting up conv3
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 770201800
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer relu3
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer relu3
I0507 15:00:35.181464  5440 net.cpp:406] relu3 <- conv3
I0507 15:00:35.181464  5440 net.cpp:367] relu3 -> conv3 (in-place)
I0507 15:00:35.181464  5440 net.cpp:122] Setting up relu3
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 810342600
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer conv4
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer conv4
I0507 15:00:35.181464  5440 net.cpp:406] conv4 <- conv3
I0507 15:00:35.181464  5440 net.cpp:380] conv4 -> conv4
I0507 15:00:35.181464  5440 net.cpp:122] Setting up conv4
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 850483400
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer relu4
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer relu4
I0507 15:00:35.181464  5440 net.cpp:406] relu4 <- conv4
I0507 15:00:35.181464  5440 net.cpp:367] relu4 -> conv4 (in-place)
I0507 15:00:35.181464  5440 net.cpp:122] Setting up relu4
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 890624200
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer conv5
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer conv5
I0507 15:00:35.181464  5440 net.cpp:406] conv5 <- conv4
I0507 15:00:35.181464  5440 net.cpp:380] conv5 -> conv5
I0507 15:00:35.181464  5440 net.cpp:122] Setting up conv5
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 930765000
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer relu5
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer relu5
I0507 15:00:35.181464  5440 net.cpp:406] relu5 <- conv5
I0507 15:00:35.181464  5440 net.cpp:367] relu5 -> conv5 (in-place)
I0507 15:00:35.181464  5440 net.cpp:122] Setting up relu5
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 970905800
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer pool3
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer pool3
I0507 15:00:35.181464  5440 net.cpp:406] pool3 <- conv5
I0507 15:00:35.181464  5440 net.cpp:380] pool3 -> pool3
I0507 15:00:35.181464  5440 net.cpp:122] Setting up pool3
I0507 15:00:35.181464  5440 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0507 15:00:35.181464  5440 net.cpp:137] Memory required for data: 980941000
I0507 15:00:35.181464  5440 layer_factory.cpp:58] Creating layer fc6
I0507 15:00:35.181464  5440 net.cpp:84] Creating Layer fc6
I0507 15:00:35.181464  5440 net.cpp:406] fc6 <- pool3
I0507 15:00:35.181464  5440 net.cpp:380] fc6 -> fc6
I0507 15:00:35.573863  5440 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0507 15:00:37.995757  5440 net.cpp:122] Setting up fc6
I0507 15:00:37.995757  5440 net.cpp:129] Top shape: 50 4096 (204800)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 981760200
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer relu6
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer relu6
I0507 15:00:38.011389  5440 net.cpp:406] relu6 <- fc6
I0507 15:00:38.011389  5440 net.cpp:367] relu6 -> fc6 (in-place)
I0507 15:00:38.011389  5440 net.cpp:122] Setting up relu6
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 4096 (204800)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 982579400
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer drop6
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer drop6
I0507 15:00:38.011389  5440 net.cpp:406] drop6 <- fc6
I0507 15:00:38.011389  5440 net.cpp:367] drop6 -> fc6 (in-place)
I0507 15:00:38.011389  5440 net.cpp:122] Setting up drop6
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 4096 (204800)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983398600
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer fc7
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer fc7
I0507 15:00:38.011389  5440 net.cpp:406] fc7 <- fc6
I0507 15:00:38.011389  5440 net.cpp:380] fc7 -> fc7
I0507 15:00:38.011389  5440 net.cpp:122] Setting up fc7
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 128 (6400)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983424200
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer relu7
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer relu7
I0507 15:00:38.011389  5440 net.cpp:406] relu7 <- fc7
I0507 15:00:38.011389  5440 net.cpp:367] relu7 -> fc7 (in-place)
I0507 15:00:38.011389  5440 net.cpp:122] Setting up relu7
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 128 (6400)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983449800
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer fc8
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer fc8
I0507 15:00:38.011389  5440 net.cpp:406] fc8 <- fc7
I0507 15:00:38.011389  5440 net.cpp:380] fc8 -> fc8
I0507 15:00:38.011389  5440 net.cpp:122] Setting up fc8
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 16 (800)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983453000
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer sig8
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer sig8
I0507 15:00:38.011389  5440 net.cpp:406] sig8 <- fc8
I0507 15:00:38.011389  5440 net.cpp:367] sig8 -> fc8 (in-place)
I0507 15:00:38.011389  5440 net.cpp:122] Setting up sig8
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 16 (800)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983456200
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer fc9
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer fc9
I0507 15:00:38.011389  5440 net.cpp:406] fc9 <- fc8
I0507 15:00:38.011389  5440 net.cpp:380] fc9 -> fc9
I0507 15:00:38.011389  5440 net.cpp:122] Setting up fc9
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: 50 1 (50)
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983456400
I0507 15:00:38.011389  5440 layer_factory.cpp:58] Creating layer loss
I0507 15:00:38.011389  5440 net.cpp:84] Creating Layer loss
I0507 15:00:38.011389  5440 net.cpp:406] loss <- fc9
I0507 15:00:38.011389  5440 net.cpp:406] loss <- label
I0507 15:00:38.011389  5440 net.cpp:380] loss -> loss
I0507 15:00:38.011389  5440 net.cpp:122] Setting up loss
I0507 15:00:38.011389  5440 net.cpp:129] Top shape: (1)
I0507 15:00:38.011389  5440 net.cpp:132]     with loss weight 1
I0507 15:00:38.011389  5440 net.cpp:137] Memory required for data: 983456404
I0507 15:00:38.011389  5440 net.cpp:198] loss needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] fc9 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] sig8 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] fc8 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu7 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] fc7 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] drop6 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu6 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] fc6 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] pool3 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu5 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] conv5 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu4 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] conv4 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu3 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] conv3 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] pool2 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu2 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] conv2 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] pool1 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] relu1 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:198] conv1 needs backward computation.
I0507 15:00:38.011389  5440 net.cpp:200] data does not need backward computation.
I0507 15:00:38.011389  5440 net.cpp:242] This network produces output loss
I0507 15:00:38.011389  5440 net.cpp:255] Network initialization done.
I0507 15:00:38.011389  5440 solver.cpp:173] Creating test net (#0) specified by net file: examples/Depth_estimation_basedLiu/DepthEst_train_end2p_net.prototxt
I0507 15:00:38.011389  5440 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0507 15:00:38.011389  5440 net.cpp:51] Initializing net from parameters: 
name: "DepthEstimation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "examples/Depth_estimation_basedLiu/test.txt"
    batch_size: 25
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 5
    kernel_size: 11
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "sig8"
  type: "Sigmoid"
  bottom: "fc8"
  top: "fc8"
}
layer {
  name: "fc9"
  type: "InnerProduct"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0507 15:00:38.027012  5440 layer_factory.cpp:58] Creating layer data
I0507 15:00:38.027012  5440 net.cpp:84] Creating Layer data
I0507 15:00:38.027012  5440 net.cpp:380] data -> data
I0507 15:00:38.027012  5440 net.cpp:380] data -> label
I0507 15:00:38.027012  5440 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: examples/Depth_estimation_basedLiu/test.txt
I0507 15:00:38.027012  5440 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
F0507 15:00:38.027012  5440 hdf5_data_layer.cpp:31] Failed opening HDF5 file: examples/Depth_estimation_basedLiu/data/test_city1.h5
